{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# What you will learn\n\n## The problem\n\nEthiopian and Kenyan runners dominate long-distance athletics. Their success has inspired countless studies, documentaries, and debates trying to uncover why runners from these two nations seem to outperform the rest of the world.\n\n*But who is faster \u2014 Kenyan or Ethiopian runners?*\n\nTo explore this question, we\u2019ve collected official race data from hundreds of professional 10,000 m runners from both countries. Each record contains the runner\u2019s name, nationality, and finishing time.\n\nJust by looking at the data, it might seem that Kenyan runners tend to have slightly lower (faster) times \u2014 but appearances can be misleading. Random variation, race conditions, or sampling bias could all explain such differences.\n\nTo answer the question rigorously, we need a statistical approach.\nWe will use hypothesis testing, specifically, a two-sample t-test, to compare the average times of Kenyan and Ethiopian runners and determine whether the observed difference is likely to be real or just due to chance.\n\nIn this lesson, we\u2019ll move from posing the question to formulating a hypothesis, performing the test by hand, and finally reproducing it with Python on a larger dataset.\n\n## The methods\n\nIn this lesson, we will learn how to compare two groups of data and decide whether the difference we see between them is real or simply due to chance. This kind of reasoning where you weigh evidence to make decisions based on data is at the heart of both statistics and machine learning.\n\nWe will begin by introducing the idea of hypothesis testing, a structured way of asking:\n\n\u201cIs there enough evidence in the data to support a particular claim?\u201d\n\nTo do this, we will learn how to:\n\n1. Formulate null and alternative hypotheses that describe our assumptions about two groups.\n\n2. Compute summary statistics (means and variances) to describe each group.\n\n3. Use a t-statistic to measure how different two group means are, relative to their variability.\n\n4. Determine whether the observed difference is statistically significant using the concept of a p-value and a significance level (\u03b1).\n\nBefore we run any Python code, we will first understand these ideas theoretically. You will see how the t-statistic formula arises from comparing two group averages and why it\u2019s a standardized measure of difference.\n\nOnce we\u2019ve established the theory, we\u2019ll move to practice:\n\n1. Selina will show you how to compute the t-statistic by hand using small samples of run times.\n\n2. Then, Beimnet will recap the reasoning and demonstrate how to do the same test efficiently in Python, allowing us to analyze much larger datasets and visualize the results.\n\nBy the end of this lesson, you\u2019ll not only know how to perform a t-test, but also why we do it and how this same logic underpins the way we evaluate models and decisions in machine learning.\n\nFor more information on the type of test we will look at see `here https://www.khanacademy.org/math/statistics-probability/significance-tests-one-sample`_. \n\n\n## How to use this material\n*update section when course is finalised*\n\nThis material is taught as part of a 6 hour learning session. Your Kujenga instructor will have booked \na time for an in-person or online two hour session. This means you have two hours to work to do either side of the\nsession. Here is what you should do:\n\n*Before coming to the class*: You should read through this entire page. At the section on calculating a confidence interval\nfor a mean. If you get stuck look \n[here](https://www.khanacademy.org/math/statistics-probability/confidence-intervals-one-sample/estimating-population-mean/v/introduction-to-t-statistics). \nAfter that section you should simply read through and try to understand what we are doing. \n\nOnce you have read through, you should \ndownload this page as a Jupyter notebook or as Python code by clicking the links at the bottom of this page.\nYou will need to have a Python environment set up on your computer or access via Google Colab (see here for\n info on how to set that up). Please make sure you have the notebook and a Python environment set up before the class.\n\n *During class*: Your teacher will start by going through the theory for `the t-test`_. \n Please ask them questions and actively engage! \n\n# Why Do We Need a Test at All?\n\nIf we collect times from 10 Kenyan and 10 Ethiopian athletes, we might see one group\u2019s average is lower. But averages alone don\u2019t prove much; maybe that difference happened by chance. To reason rigorously, we use hypothesis testing.\nIt lets us evaluate whether the difference we observe is likely real or just random variation.\n\nHere in this lesson, we want to answer the question: Who is faster? Kenyan or Ethiopian runners? And more specifically, since in this lesson we'll only cover one-sided t-tests, we'll reframe the question to be: Are Kenyan runners faster than Ethiopian runners? \n\nWe\u2019ll then set our hypothesis to be tested as follows:\n\n *Kenyan runners have a lower average time (are faster) than Ethiopian runners.*\n\nTo test this, we set up two competing hypotheses:\n\n1. **Null Hypothesis (H\u2080)**: Kenyan and Ethiopian runners have the same average time. Any difference we see is due to random chance.\n2. **Alternative Hypothesis (H\u2081)**: Kenyan runners have a lower average time (are faster) than Ethiopian runners.\n\nAnd mathematically, we can express these hypotheses as:\n\n\\begin{align}H_0: \\mu_{\\mathrm{Kenya}} \\geq \\mu_{\\mathrm{Ethiopia}}  \n\n    H_1: \\mu_{\\mathrm{Kenya}} < \\mu_{\\mathrm{Ethiopia}}\\end{align}\n\nWhere $\\mu$ represents the population mean time for each group.\n\n# Calculating the t-Statistic by Hand\n\nIn the following short video, Selina takes 10 times from each group, computes their averages, and applies the t-statistic formula:\n\n\n\\begin{align}t = \\frac{\\overline{X}_1 - \\overline{X}_2} {\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\\end{align}\n\nShe then compares her result to a critical value to decide whether the Kenyan runners are significantly faster.\n\nTake a few minutes to watch her work through the math, notice how each part of the formula measures either difference in means or variation within each group.\n\n.. youtube:: 5p8jcxIs4CA\n    :width: 100% \n    :align: center \n\n\n# Doing it in Python\nNow that you\u2019ve seen how to compute a t-statistic by hand, let\u2019s review what those numbers mean. \nIn the next video, Beimnet recaps the reasoning behind the t-test and shows how to implement it in Python. \nThis allows us to analyze much larger datasets efficiently.\n\n.. youtube:: kE8KCy1ErWE\n    :width: 100% \n    :align: center\n\nIn this video:\n\n1. We briefly recap what the null and alternative hypotheses represent,\n\n2. explain why the significance level (\u03b1) matters, and\n\n3. show how to perform the same t-test using Python \u2014 automating all the calculations Selina did manually.\n\nThis notebook complements that video by letting you run and modify the same code yourself.\nYou\u2019ll find each step below with explanations so you can experiment freely.\n\n\n## Loading in the data set\nLet\u2019s load our dataset of race times and prepare it for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n\n# Load in times of runners\nETH_data = pd.read_csv('../data/ethiopia_10000m_runners.csv')\nKEN_data= pd.read_csv('../data/kenyan_10000m_runners.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sampling and Comparing the Two Groups\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "#  Selina used 10 runners from each group; let\u2019s do the same here.\n\neth_data = ETH_data.sample(n=10, random_state=1)['Mark'].tolist()\nken_data = KEN_data.sample(n=10, random_state=2)['Mark'].tolist()\nprint(f\"ETH DATA: {eth_data}\")\nprint(f\"KEN DATA: {ken_data}\")\n\n# Now, let\u2019s compare their averages:\nfrom statistics import mean\nprint(\"Average Ethiopian time:\" ,mean(eth_data))\nprint(\"Average Kenyan time\", mean(ken_data) )\n# We see that the Kenyan runners have a lower average time, but is this difference significant?\n# To answer that, we need to compute the t-statistic and compare it to a critical value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running the t-Test in Python\nNow that we\u2019ve set up our two samples and calculated their averages, we\u2019re ready to formally test our hypothesis.\nJust as we did by hand, we\u2019ll now use a t-test, but this time, Python will handle all the calculations for us.\n\nThe function ttest_ind() from the scipy.stats library performs a two-sample t-test.\nWe\u2019ll specify that we\u2019re running a one-sided test (since we\u2019re testing whether Kenyan runners are faster, not just different).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n\nt_stat, p_value= ttest_ind(ken_data, eth_data, alternative='less', equal_var=False)\nprint(\"T-statistics:\", t_stat)\nprint(\"P-value:\", p_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s unpack what this means:\n\n* t-statistic: measures how far apart the two sample means are, relative to the variation within each group.\n\n* p-value: tells us the probability of observing such a difference (or one more extreme) if the null hypothesis were true. In other words, if there were no real difference between the groups.\n\nThe smaller the p-value, the less likely it is that our observed difference happened just by random chance.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Making a Decision and Interpreting the Result\nIn statistics, we need a rule to decide when a difference is significant enough to reject the null hypothesis.\nThat\u2019s where the significance level, usually denoted by \ud835\udefc comes in.\nA common choice is \ud835\udefc = 0.05, meaning we accept a 5% risk of being wrong when concluding there\u2019s a difference.\n\nLet\u2019s apply that rule to our result:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "alpha = 0.05\n\nif p_value < alpha:\n    print(\"Reject the null hypothesis: Kenyan runners are statistically faster.\")\nelse:\n    print(\"Fail to reject the null hypothesis: No significant difference found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the p-value is smaller than 0.05, it means the data provide strong evidence against the null hypothesis,\njust as Selina found in her manual example.\nBut rather than computing it step by step, Python gives us a fast, reliable result that scales easily to much larger datasets.\n\nThis mirrors exactly what Selina did by hand, just powered by Python. The goal isn\u2019t to replace the math, but to use it at scale and interpret the evidence more efficiently.\n\n## Checking the Critical Value\nIf you recall, in her video, Selina calculated the t-statistic and compared it to something called a critical value.\nThis value acts like a cutoff point: it tells us how extreme our t-statistic must be before we decide the difference between groups is statistically significant.\nIn other words, If our calculated t-statistic is more extreme than the critical value, the result is unlikely to have happened by chance \u2014 so we reject the null hypothesis.\nWe can calculate this value directly in Python using the same logic Selina used by hand.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.stats import t\n\ndf = len(KEN_data) + len(ETH_data) - 2   # degrees of freedom (approximation)\nalpha = 0.05                    # our significance level\ncritical_value = t.ppf(1 - alpha, df)\n\nprint(\"Critical Value:\", critical_value)\nprint(\"Observed t-statistic:\", t_stat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here\u2019s how to interpret what you see:\n\n* Critical Value: the threshold beyond which a result is considered statistically significant.\n* t_statistic: our observed difference between the two groups, scaled by their variability.\n\nIf the t-statistic is smaller (more negative) than our critical value, it means our observed difference is strong enough to reject H_0.\nBy checking both the p-value and the critical value, we see two sides of the same reasoning:\n\n* The p-value tells us how likely our result is if the null hypothesis were true.\n* The critical value tells us how far our result needs to go before we can call it significant.\n\nTogether, they give us both intuition and mathematical confirmation \u2014 a solid foundation for making data-driven conclusions.\n\n## Visualizing the Distributions\n\nBefore we move on, let\u2019s take a moment to see what our data look like.\nStatistics often become much clearer when we visualize them, especially when comparing two groups.\n\nBy plotting the distribution of race times for both Ethiopian and Kenyan runners, we can get a quick visual impression of whether one group tends to have lower (faster) times than the other.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\nplt.hist(ETH_data['Mark'], bins=10, alpha=0.6, label='Ethiopian Runners')\nplt.hist(KEN_data['Mark'], bins=10, alpha=0.6, label='Kenyan Runners')\nplt.xlabel('Time (seconds)')\nplt.ylabel('Frequency')\nplt.legend()\nplt.title('Distribution of 10,000m Race Times')\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If our hypothesis is correct, we might expect to see the Kenyan distribution slightly shifted to the left, toward smaller times.\n This would visually confirm what our t-test already suggested: that Kenyan runners tend to record faster race times on average.\n\n In statistics, visualization and computation go hand in hand.\n A plot helps you build intuition for what the numbers are saying. \n The t-test gives you the exact measure of confidence, but the plot gives you a story, it helps you see patterns, \n overlap, and how much the two groups differ in real terms.\n By comparing both, we can move beyond just accepting or rejecting a hypothesis and \n start understanding what the data are actually telling us. \n\n\n\n .. youtube:: spuHjliHpw0\n    :width: 100% \n    :align: center \n\n\n Exercise: Evaluating a Coach's Claim about Training Methods\n =============================================================== \n Below is an example that we can attempt. In this exercise you will apply your knowledge of hypothesis testing to evaluate a coaches claim about training methods\n\n * Scenario \n A running coach believes that training at high altitutde improves athletes' 10,000-meter race performance. According to the coach, athletes who train at higher evaltion have better oxygen-utilisation effeciency, resulting in faster race times\n To asses this claim, the coach records the race times (in seconds) for 50 athletes \n * 35 athletes trained at High Altitude (HA)\n * 25 athletes trained at Low Altitude (SL)\n Your task is to statistically determine whether high-altitude athletes are indeed significantly faster\n Your task \n *Define your null hypothesis H_0 and teh alternative hypothesis H_1\n * What does the coach's claim imply?\n * Should this be a one sided test or a two sided test?\n########################################################\n Use the dataset below \n This dataset contains the race times recorded by the coach\n\n High Altitude (HA) Group - 25 athletes\n HA = [\n     1931.2, 1928.4, 1942.1, 1919.7, 1935.3,\n     1922.8, 1917.4, 1940.9, 1938.2, 1926.5,\n     1933.1, 1924.6, 1930.4, 1918.9, 1936.7,\n     1921.3, 1941.5, 1934.2, 1916.8, 1929.9,\n     1937.4, 1923.1, 1932.8, 1927.6, 1919.3\n ]\n\n Sea Altitude (SL) Group - 25 athletes\n SL = [\n     1958.6, 1961.9, 1949.5, 1965.2, 1953.8,\n     1962.3, 1947.9, 1956.7, 1970.1, 1959.4,\n     1963.8, 1950.7, 1966.4, 1948.8, 1961.2,\n     1957.9, 1972.6, 1960.5, 1954.1, 1968.3,\n     1952.7, 1971.4, 1955.9, 1964.8, 1958.1\n ]\n\n Perform a t-test\n Use scipy.stats.ttest_ind():\n * Choose whether the test should be alternative=\"less\" or \"two-sided\".\n * Decide whether equal variances can be assumed.\n Interpret your results\n Answer the following:\n\n * What does the p-value indicate about the coach\u2019s claim?\n * Should you reject or fail to reject the null hypothesis?\n * Do the results support the idea that high-altitude training improves performance?\n * Visualize the comparison\n\n Create:\n * A boxplot\n * A histogram\n * Or any plot that helps you compare the distributions\n\n Discuss what you observe visually.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}